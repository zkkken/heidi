"""
core/ai_locator.py
AI Vision Core v3.0 - Auto-Scale, Crop & Refine, Batch Extraction
"""
import os
import base64
import json
import time
import re
import io
from typing import Dict, Optional, Tuple, List
import pyautogui
from anthropic import Anthropic
from rich.console import Console
from PIL import Image, ImageDraw

# å¼•ç”¨é…ç½®
from .config import DEBUG_MODE, SCREENSHOT_OUTPUT_DIR

console = Console()


class AINavigator:
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        if not self.api_key:
            console.print("[yellow]âš ï¸  æœªé…ç½® ANTHROPIC_API_KEYï¼ŒAI åŠŸèƒ½å°†ä¸å¯ç”¨[/yellow]")

        self.client = Anthropic(api_key=self.api_key) if self.api_key else None
        self.model = os.getenv("AI_MODEL_NAME", "claude-3-5-sonnet-20241022")
        # é€»è¾‘åˆ†è¾¨ç‡ (ç”¨äºé¼ æ ‡ç‚¹å‡»)
        self.screen_w, self.screen_h = pyautogui.size()

    def _get_pixel_scale(self, image: Image.Image) -> float:
        """
        è®¡ç®—ç‰©ç†åƒç´ ä¸é€»è¾‘åƒç´ çš„æ¯”ä¾‹ (è§£å†³ Retina å±ç‚¹å‡»ä¸å‡†çš„æ ¸å¿ƒ)
        ä¾‹å¦‚ï¼šæˆªå›¾å®½ 3024ï¼Œå±å¹•å®½ 1512 -> æ¯”ä¾‹ 2.0
        """
        img_w, _ = image.size
        scale = img_w / self.screen_w
        return scale

    def _encode_pil_image(self, image: Image.Image) -> str:
        """å°† PIL Image ç¼–ç ä¸º base64"""
        buffered = io.BytesIO()
        image.save(buffered, format="PNG")
        return base64.b64encode(buffered.getvalue()).decode('utf-8')

    def _encode_image(self, image_path: str) -> str:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')

    def _debug_draw_points(self, image_path: str, coords: List[Dict], tag: str = "debug"):
        """åœ¨æˆªå›¾ä¸Šç”»å‡ºè¯†åˆ«ç‚¹ï¼Œç”¨äºè°ƒè¯•"""
        if not DEBUG_MODE: return
        try:
            img = Image.open(image_path)
            draw = ImageDraw.Draw(img)
            for idx, item in enumerate(coords):
                x, y = item['x'], item['y']
                name = item.get('name', 'Unknown')
                r = 10
                draw.ellipse((x-r, y-r, x+r, y+r), outline="red", width=3)
                draw.text((x+15, y), f"#{idx+1}: {name}", fill="red")
            
            save_path = SCREENSHOT_OUTPUT_DIR / f"ai_vision_{tag}_{int(time.time())}.png"
            img.save(save_path)
            console.print(f"[yellow]ğŸ” [Debug] è§†è§‰æ ‡è®°å·²ä¿å­˜: {save_path}[/yellow]")
        except Exception as e:
            console.print(f"[red]ç”»å›¾å¤±è´¥: {e}[/red]")

    def _extract_json_from_text(self, text: str) -> Optional[Dict]:
        """
        é²æ£’çš„ JSON æå–å™¨ï¼Œè§£å†³ 'Extra data' é—®é¢˜
        """
        text = text.strip()
        try:
            # 1. å°è¯•ç›´æ¥è§£æ
            return json.loads(text)
        except json.JSONDecodeError:
            pass

        try:
            # 2. æå–ç¬¬ä¸€ä¸ª { ... } ä»£ç å—
            match = re.search(r'(\{.*?\})', text, re.DOTALL)
            if match:
                return json.loads(match.group(1))
            
            # 3. æå– ```json ... ``` åŒ…è£¹çš„å†…å®¹
            match = re.search(r'```json(.*?)```', text, re.DOTALL)
            if match:
                return json.loads(match.group(1).strip())
        except Exception as e:
            console.print(f"[red]JSON è§£æå¤±è´¥: {e}[/red]")
            console.print(f"[dim]åŸå§‹å†…å®¹: {text[:100]}...[/dim]")
        return None

    def _call_claude_json(self, image_path: str, prompt: str) -> Optional[Dict]:
        """å‘é€è¯·æ±‚å¹¶è·å– JSON"""
        b64_data = self._encode_image(image_path)
        try:
            if DEBUG_MODE:
                console.print(f"[dim]AI è¯·æ±‚ä¸­ ({self.model})...[/dim]")
            
            response = self.client.messages.create(
                model=self.model,
                max_tokens=2048,
                system="You are a UI Automation Agent. Return ONLY valid JSON. Do not write explanations.",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": b64_data}},
                        {"type": "text", "text": prompt}
                    ]
                }]
            )
            return self._extract_json_from_text(response.content[0].text)
        except Exception as e:
            console.print(f"[red]AI Request Error: {e}[/red]")
            return None

    def locate_all_visible_patients(self, screenshot_path: str) -> List[Dict]:
        """
        [ç²¾å‡†æ‰¹é‡è¯†åˆ« - CareFlow ä¼˜åŒ–ç‰ˆ]
        """
        prompt = f"""
        Analyze this **CareFlow EMR** screenshot (Resolution: {self.screen_w}x{self.screen_h}).
        
        **Objective**: Identify all patient rows in the MAIN TABLE.

        **Critical Layout Analysis**:
        1.  **IGNORE the Left Sidebar**: Do NOT select "All Patients" or "Active Patients" in the dark/gray sidebar on the left.
        2.  **Focus on Main Content**: Look for the large white table area on the right.
        3.  **Find the Header**: Locate the row with "Name", "Date of birth", "Gender".
        4.  **Align with "Name"**: The targets are the **Blue Clickable Names** strictly vertically aligned under the "Name" header.

        **Task**:
        - Scan the table from top to bottom.
        - For each row, extract the Patient Name.
        - Return the **Center (x,y)** of the name text as **Relative Percentages (0.0-1.0)**.

        **Output JSON**:
        {{
            "patients": [
                {{ "name": "Diana Rossi", "x_percent": 0.25, "y_percent": 0.35 }},
                ...
            ]
        }}
        """
        
        data = self._call_claude_json(screenshot_path, prompt)
        
        results = []
        if data and "patients" in data:
            for p in data["patients"]:
                results.append({
                    "name": p.get("name", "Unknown"),
                    "x": int(p["x_percent"] * self.screen_w),
                    "y": int(p["y_percent"] * self.screen_h)
                })
        
        # è°ƒè¯•ç”»å›¾
        if results:
            self._debug_draw_points(screenshot_path, results, tag="patients_fix")
            
        return results

    def extract_patient_details(self, screenshot_path: str) -> Optional[Dict]:
        """æå–è¯¦æƒ…é¡µæ•°æ®"""
        prompt = """
        Extract patient details from this profile page.
        Required Fields: first_name, last_name, gender (MALE/FEMALE/OTHER), birth_date (YYYY-MM-DD), ehr_patient_id.
        
        Return JSON object only. No markdown formatting.
        Example: {"first_name": "John", ...}
        """
        return self._call_claude_json(screenshot_path, prompt)

    # --- å…¼å®¹æ—§æ¥å£ ---
    def find_tab_or_button(self, screenshot_path: str, target_name: str) -> Optional[Tuple[int, int]]:
        prompt = f"Find the button or tab labeled '{target_name}'. Return JSON: {{'found': true, 'x_percent': 0.5, 'y_percent': 0.5}}"
        data = self._call_claude_json(screenshot_path, prompt)
        if data and data.get("found"):
            return int(data["x_percent"] * self.screen_w), int(data["y_percent"] * self.screen_h)
        return None

    def extract_free_text(self, screenshot_path: str) -> str:
        # è¿™ä¸ªæ–¹æ³•è¿”å›çº¯æ–‡æœ¬ï¼Œä¸éœ€è¦ JSON è§£æ
        b64 = self._encode_image(screenshot_path)
        try:
            resp = self.client.messages.create(
                model=self.model, max_tokens=2048,
                messages=[{"role": "user", "content": [{"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": b64}}, {"type": "text", "text": "OCR this text."}]}]
            )
            return resp.content[0].text
        except:
            return ""

    # =========================================================
    # v3.0 æ–°åŠŸèƒ½: æ‰¹é‡å»ºæ¡£ & äºŒæ¬¡æˆªå›¾ç²¾å‡†å®šä½
    # =========================================================

    def _call_claude(self, b64_image: str, prompt: str) -> Optional[Dict]:
        """å‘é€ base64 å›¾ç‰‡å¹¶è·å– JSON å“åº”"""
        if not self.client:
            console.print("[red]âŒ AI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–[/red]")
            return None

        try:
            response = self.client.messages.create(
                model=self.model,
                max_tokens=4096,
                system="Output strictly valid JSON only. No text explanations.",
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": b64_image}},
                        {"type": "text", "text": prompt}
                    ]
                }]
            )
            return self._extract_json_from_text(response.content[0].text)
        except Exception as e:
            console.print(f"[red]AI Error: {e}[/red]")
            return None

    def extract_patient_list_data(self, screenshot_path: str) -> List[Dict]:
        """
        [æ‰¹é‡å»ºæ¡£æ¨¡å¼] ç›´æ¥ä»åˆ—è¡¨é¡µ OCR æå–æ‰€æœ‰ç—…äººçš„ç»“æ„åŒ–æ•°æ®
        ä¸å†è¿”å›åæ ‡ï¼Œè€Œæ˜¯è¿”å› {first_name, last_name, dob, gender...}
        """
        img = Image.open(screenshot_path)
        b64 = self._encode_pil_image(img)

        prompt = """
        Analyze this EMR patient list table.
        Extract data for **EVERY** visible patient row into a structured JSON list.

        **Columns to Map:**
        - Name -> split into `first_name`, `last_name`
        - Date of birth -> `birth_date` (Format: YYYY-MM-DD)
        - Gender -> `gender` (MALE/FEMALE)
        - Email/Phone -> put in `additional_context` string
        - Patient ID -> if hidden, leave null.

        **Output Format:**
        {
            "patients": [
                {
                    "first_name": "Diana",
                    "last_name": "Rossi",
                    "birth_date": "1998-04-03",
                    "gender": "FEMALE",
                    "additional_context": "Phone: (415)... Email: ..."
                },
                ...
            ]
        }
        """

        console.print("[cyan]ğŸ” AI æ­£åœ¨è¯»å–åˆ—è¡¨æ•°æ®...[/cyan]")
        data = self._call_claude(b64, prompt)

        if data and "patients" in data:
            return data["patients"]
        return []

    def locate_patient_precise(self, screenshot_path: str, target_desc: str = "first patient row") -> Optional[Tuple[int, int]]:
        """
        [ç²¾å‡†ç‚¹å‡»æ¨¡å¼] äºŒæ¬¡æˆªå›¾æŠ€æœ¯
        Step 1: æ‰¾å¤§åŒºåŸŸ (Table)
        Step 2: è£å‰ª
        Step 3: æ‰¾ç²¾ç¡®ç‚¹
        """
        img = Image.open(screenshot_path)
        scale = self._get_pixel_scale(img)  # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹

        # --- Step 1: ç²—å®šä½åŒºåŸŸ ---
        console.print("[dim]Phase 1: è¯†åˆ«è¡¨æ ¼åŒºåŸŸ...[/dim]")
        global_prompt = """
        Identify the bounding box of the **Main Patient Data Table** (excluding the left sidebar and top navigation).
        Focus on the area containing the list of names.

        Return JSON: { "bbox": [ymin, xmin, ymax, xmax] }  (0.0-1.0 relative coords)
        """
        b64_global = self._encode_pil_image(img)
        res_global = self._call_claude(b64_global, global_prompt)

        if not res_global or "bbox" not in res_global:
            console.print("[red]âŒ æ— æ³•è¯†åˆ«è¡¨æ ¼åŒºåŸŸ[/red]")
            return None

        # è®¡ç®—è£å‰ªåæ ‡ (ç‰©ç†åƒç´ )
        ymin, xmin, ymax, xmax = res_global["bbox"]
        width, height = img.size

        crop_box = (
            int(xmin * width),
            int(ymin * height),
            int(xmax * width),
            int(ymax * height)
        )

        # --- Step 2: è£å‰ª ---
        cropped_img = img.crop(crop_box)
        # è°ƒè¯•ï¼šä¿å­˜è£å‰ªå›¾
        if DEBUG_MODE:
            crop_path = SCREENSHOT_OUTPUT_DIR / "debug_crop.png"
            cropped_img.save(crop_path)
            console.print(f"[dim]è£å‰ªåŒºåŸŸå·²ä¿å­˜: {crop_path}[/dim]")

        # --- Step 3: ç²¾å®šä½ ---
        console.print(f"[dim]Phase 2: åœ¨å±€éƒ¨åŒºåŸŸç²¾ç¡®æŸ¥æ‰¾ '{target_desc}'...[/dim]")
        local_prompt = f"""
        This is a cropped view of the patient list.
        Locate the **{target_desc}** (e.g. the Name text itself).

        Return the center coordinates relative to THIS cropped image (0.0-1.0).
        JSON: {{ "found": true, "x": 0.5, "y": 0.1 }}
        """
        b64_local = self._encode_pil_image(cropped_img)
        res_local = self._call_claude(b64_local, local_prompt)

        if res_local and res_local.get("found"):
            # åæ ‡è¿˜åŸé€»è¾‘
            # 1. å°å›¾ç›¸å¯¹ -> å°å›¾ç»å¯¹
            local_x = res_local["x"] * (crop_box[2] - crop_box[0])
            local_y = res_local["y"] * (crop_box[3] - crop_box[1])

            # 2. å°å›¾ç»å¯¹ -> å¤§å›¾ç»å¯¹ (ç‰©ç†åƒç´ )
            global_x_px = crop_box[0] + local_x
            global_y_px = crop_box[1] + local_y

            # 3. ç‰©ç†åƒç´  -> é€»è¾‘åƒç´  (é™¤ä»¥ scale)
            final_x = int(global_x_px / scale)
            final_y = int(global_y_px / scale)

            console.print(f"[green]ğŸ¯ åæ ‡æ ¡å‡†: ç‰©ç†({int(global_x_px)},{int(global_y_px)}) -> é€»è¾‘({final_x},{final_y}) (Scale: {scale:.1f})[/green]")
            return final_x, final_y

        console.print("[red]âŒ ç²¾ç¡®å®šä½å¤±è´¥[/red]")
        return None

    # =========================================================
    # å…¼å®¹æ—§æ¥å£
    # =========================================================

    def locate_with_layout_analysis(self, screenshot_path: str, user_target_desc: str) -> Optional[Tuple[int, int]]:
        """å…¼å®¹æ—§æ¥å£ - ä½¿ç”¨ç²¾å‡†å®šä½"""
        return self.locate_patient_precise(screenshot_path, user_target_desc)

    def extract_page_data(self, screenshot_path: str, context_data: Optional[Dict] = None) -> Dict:
        """å…¼å®¹æ—§æ¥å£"""
        data = self.extract_patient_details(screenshot_path)
        if data:
            return {
                "patient_info": data,
                "is_complete": True,
                "next_action": {"type": "finish", "reason": "Data extracted successfully"}
            }
        return {
            "patient_info": {},
            "is_complete": True,
            "next_action": {"type": "finish", "reason": "Extraction failed"}
        }

    def locate_patient_row_universal(self, screenshot_path: str) -> Optional[Tuple[int, int]]:
        """å…¼å®¹æ—§æ¥å£ - ä½¿ç”¨ç²¾å‡†å®šä½"""
        return self.locate_patient_precise(screenshot_path, "First patient Name text")

    def extract_profile_details(self, screenshot_path: str) -> Optional[Dict]:
        """ä»è¯¦æƒ…é¡µæå–å®Œæ•´ç—…äººä¿¡æ¯"""
        img = Image.open(screenshot_path)
        prompt = """
        Extract full patient details from this profile page.
        Include: first_name, last_name, birth_date (YYYY-MM-DD), gender (MALE/FEMALE/OTHER),
        ehr_patient_id, and any additional information like history, notes, phone, email.

        Return JSON: {
            "first_name": "...",
            "last_name": "...",
            "birth_date": "YYYY-MM-DD",
            "gender": "MALE/FEMALE/OTHER",
            "ehr_patient_id": "...",
            "additional_context": "any extra info..."
        }
        """
        return self._call_claude(self._encode_pil_image(img), prompt)